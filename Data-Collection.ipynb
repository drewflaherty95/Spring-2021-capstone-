{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "This file contains the code for all of the data collection for this project. The data was collected from the SEC edgar database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "import pandas as pd\n",
    "from json import JSONDecodeError\n",
    "import time\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "These functions will be used later in the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function creates the url for the daily index files that will be pulled\n",
    "def make_url(base_url, comp):\n",
    "  url = base_url\n",
    "  for r in comp:\n",
    "    url='{}/{}'.format(url,r)\n",
    "  return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function uses multithreading to scrape webpages faster than a loop would\n",
    "#It outputs the time it takes to pull the specified number of items\n",
    "#Make sure this number stays above 1 second per 10 items or edgar will block you from scraping\n",
    "def main(func, lst, num_workers):\n",
    "    t0 = time.time()\n",
    "    #create list of lists containing file counts for each type of file\n",
    "    with ThreadPool(num_workers) as pool:\n",
    "      df_lst = pool.map(func, lst)\n",
    "    t1 = time.time()\n",
    "    print(f\"{(t1-t0)} seconds to read {len(lst)} items.\")\n",
    "    return df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grabbing the daily index files\n",
    "#the daily index files contain information on all documents that were filed on a particular day\n",
    "file_lst=[]\n",
    "years = range(1994, 2022, 1)\n",
    "year_lst=[]\n",
    "base_url=r'https://www.sec.gov/Archives/edgar/daily-index'\n",
    "#loop through every year in the directory\n",
    "for year in years:\n",
    "  year = str(year)\n",
    "#This url collects the files\n",
    "  year_url = make_url(base_url, [year,'index.json'])\n",
    "  \n",
    "  content = requests.get(year_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "  decoded_content = content.json()\n",
    "#get the url for every quarter in the directory\n",
    "  for item in decoded_content['directory']['item']:\n",
    "    qtr_url = make_url(base_url, [year, item['name'], 'index.json'])\n",
    "\n",
    "    file_content = requests.get(qtr_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    decoded_content=file_content.json()\n",
    "# get file urls for every quarter\n",
    "    for file in decoded_content['directory']['item']:\n",
    "      file_url=make_url(base_url, [year, item['name'], file['name']])\n",
    "      file_lst.append(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes the master files and puts them into one list\n",
    "master_idx=[]\n",
    "for file in file_lst:\n",
    "  if 'master' in file:\n",
    "    master_idx.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this loop creates a list of dictionaries for forms that were filed for the quarters that were previously pulled\n",
    "error_idx=[]\n",
    "master_lst=[]\n",
    "for index, item in enumerate(master_idx):\n",
    "#open and read each file url in the master list\n",
    "#this decodes the bytes into a list where the later indices of the list have file information\n",
    "  file_url=item.replace('.gz', '')\n",
    "  content = requests.get(file_url, headers={'User-Agent': 'Mozilla/5.0'}).content\n",
    "\n",
    "  with open('master_url.txt', 'wb') as f:\n",
    "    f.write(content)\n",
    "\n",
    "  with open('master_url.txt', 'rb') as f:\n",
    "    byte_data = f.read()\n",
    "    #There were errors in decoding some of the files so I skipped those\n",
    "  try:\n",
    "    data = byte_data.decode('utf-8').split('  ')\n",
    "  except UnicodeDecodeError:\n",
    "    error_idx.append(index)\n",
    "    continue\n",
    "\n",
    "#find the index in the data list where file info starts\n",
    "  for index, item in enumerate(data):\n",
    "    if 'data/' in item:\n",
    "      start_idx = index\n",
    "      break\n",
    "\n",
    "  data_format = data[start_idx:]\n",
    "#Only include indices that have file info, so anything with a length of zero isn't useful\n",
    "  data_reformatted=[]\n",
    "  for index, item in enumerate(data_format):\n",
    "    if len(item) !=0:\n",
    "      data_reformatted.append(item)\n",
    "\n",
    "  master_data = []\n",
    "#loop through data list\n",
    "  for index, item in enumerate(data_reformatted):\n",
    "        #some stuff at the beginning of this long list needs to be removed\n",
    "    if index==0:\n",
    "      clean_item_data=item.replace('\\n', '|').split('|')\n",
    "      #clean_item_data=clean_item_data[8:]\n",
    "    else:\n",
    "      clean_item_data=item.replace('\\n', '|').split('|')\n",
    "#grab all item that end in .txt because that indicates the file name\n",
    "    for index, row in enumerate(clean_item_data):\n",
    "      if '.txt' in row:\n",
    "        mini_lst = clean_item_data[(index-4):index+1]\n",
    "#create the url to grab the file\n",
    "        if len(mini_lst) != 0:\n",
    "          mini_lst[4]='https://www.sec.gov/Archives/' + mini_lst[4]\n",
    "          \n",
    "          master_data.append(mini_lst)\n",
    "#create a dictionary that will be added to the master list of all files\n",
    "  for index, document in enumerate(master_data):\n",
    "    document_dict={}\n",
    "    document_dict['cik'] = document[0]\n",
    "    document_dict['company'] = document[1]\n",
    "    document_dict['form'] = document[2]\n",
    "    document_dict['date'] = document[3]\n",
    "    document_dict['url'] = document[4]\n",
    "\n",
    "    master_data[index]=document_dict\n",
    "  master_lst.append(master_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pull 10-k and 10-q files from master list\n",
    "quarterly_list=[]\n",
    "yearly_list=[]\n",
    "for master_data in master_lst:\n",
    "    for document_dict in master_data:\n",
    "        if document_dict['form']=='10-Q':\n",
    "            quarterly_list.append(document_dict)\n",
    "        if document_dict['form']=='10-K':\n",
    "            yearly_list.append(document_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert both to dataframes to save for later\n",
    "quarterly_df = pd.DataFrame(quarterly_list)\n",
    "quarterly_df.to_csv('10-Q.csv')\n",
    "\n",
    "yearly_df = pd.DataFrame(yearly_list)\n",
    "yearly_df.to_csv('10-K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>form</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275605</td>\n",
       "      <td>GENERAL HOST CORP</td>\n",
       "      <td>19940701</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/data/40638/000095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61425</td>\n",
       "      <td>GIANT FOOD INC</td>\n",
       "      <td>19940701</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/data/41289/000004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>763043</td>\n",
       "      <td>UNIVAR CORP</td>\n",
       "      <td>19940628</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/data/101929/00001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800042</td>\n",
       "      <td>HARNISCHFEGER INDUSTRIES INC</td>\n",
       "      <td>19940614</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/data/801898/00008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>841289</td>\n",
       "      <td>RITE AID CORP</td>\n",
       "      <td>19940628</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/data/84129/000089...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cik                       company      date  form  \\\n",
       "0  275605             GENERAL HOST CORP  19940701  10-Q   \n",
       "1   61425                GIANT FOOD INC  19940701  10-Q   \n",
       "2  763043                   UNIVAR CORP  19940628  10-Q   \n",
       "3  800042  HARNISCHFEGER INDUSTRIES INC  19940614  10-Q   \n",
       "4  841289                 RITE AID CORP  19940628  10-Q   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.sec.gov/Archives/data/40638/000095...  \n",
       "1  https://www.sec.gov/Archives/data/41289/000004...  \n",
       "2  https://www.sec.gov/Archives/data/101929/00001...  \n",
       "3  https://www.sec.gov/Archives/data/801898/00008...  \n",
       "4  https://www.sec.gov/Archives/data/84129/000089...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load 10-q file info\n",
    "quarterly_df=pd.read_csv('10-Q.csv')\n",
    "quarterly_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "quarterly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cik': 275605,\n",
       "  'company': 'GENERAL HOST CORP',\n",
       "  'date': 19940701,\n",
       "  'form': '10-Q',\n",
       "  'url': 'https://www.sec.gov/Archives/data/40638/0000950124-94-001209.txt'},\n",
       " {'cik': 61425,\n",
       "  'company': 'GIANT FOOD INC',\n",
       "  'date': 19940701,\n",
       "  'form': '10-Q',\n",
       "  'url': 'https://www.sec.gov/Archives/data/41289/0000041289-94-000003.txt'},\n",
       " {'cik': 763043,\n",
       "  'company': 'UNIVAR CORP',\n",
       "  'date': 19940628,\n",
       "  'form': '10-Q',\n",
       "  'url': 'https://www.sec.gov/Archives/data/101929/0000101929-94-000016.txt'},\n",
       " {'cik': 800042,\n",
       "  'company': 'HARNISCHFEGER INDUSTRIES INC',\n",
       "  'date': 19940614,\n",
       "  'form': '10-Q',\n",
       "  'url': 'https://www.sec.gov/Archives/data/801898/0000801898-94-000010.txt'},\n",
       " {'cik': 841289,\n",
       "  'company': 'RITE AID CORP',\n",
       "  'date': 19940628,\n",
       "  'form': '10-Q',\n",
       "  'url': 'https://www.sec.gov/Archives/data/84129/0000893220-94-000311.txt'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to list of dictionaries\n",
    "quarterly_list=quarterly_df.to_dict('records')\n",
    "quarterly_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grab 1/8 of list for time purposes\n",
    "quarterly_4=quarterly_list[482004:562398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quarterly_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function grabs the xml link that has a summary of all of the financial statements in the report\n",
    "def get_xml(dictionary):\n",
    "  time.sleep(0.7)\n",
    "  base_url='https://www.sec.gov'\n",
    "  base_dict = {}\n",
    "  base_dict['cik'] = dictionary['cik']\n",
    "  if 'data/' in dictionary['url']:\n",
    "    documents_url = dictionary['url'].replace('-','').replace('.txt', '/index.json')\n",
    "    try:\n",
    "        content=requests.get(documents_url, headers={'User-Agent': 'Mozilla/5.0'}).json()\n",
    "    except JSONDecodeError:\n",
    "        return base_dict\n",
    "    xml_summary = ''\n",
    "    #loop through the documents_url webpage to find the xml summary link\n",
    "    for file in content['directory']['item']:\n",
    "        if file['name'] == 'FilingSummary.xml':\n",
    "            xml_summary = base_url + content['directory']['name']+'/'+file['name']\n",
    "            xml_dict={}\n",
    "            xml_dict['cik'] = dictionary['cik']\n",
    "            xml_dict['date'] = dictionary['date']\n",
    "            xml_dict['xml'] = xml_summary\n",
    "            \n",
    "            return xml_dict\n",
    "    if len(xml_summary)==0:\n",
    "      return base_dict\n",
    "\n",
    "  else:\n",
    "    return base_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10593.458915233612 seconds to read 80394 items.\n"
     ]
    }
   ],
   "source": [
    "#run main function\n",
    "xml_list = main(get_xml, quarterly_4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76391"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sometime the url won't read correctly. this loop gets rid of those\n",
    "new_xml=[]\n",
    "for i in range(len(xml_list)):\n",
    "    if len(xml_list[i])==3:\n",
    "        new_xml.append(xml_list[i])\n",
    "len(new_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv for later\n",
    "xml_qtr = pd.DataFrame(xml_list)\n",
    "xml_qtr.to_csv('10-Q_xml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "      <th>xml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084048</td>\n",
       "      <td>20161109.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084961</td>\n",
       "      <td>20161109.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1087934</td>\n",
       "      <td>20161109.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/108793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1091171</td>\n",
       "      <td>20161109.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1092289</td>\n",
       "      <td>20161109.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109228...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cik        date                                                xml\n",
       "0  1084048  20161109.0  https://www.sec.gov/Archives/edgar/data/108404...\n",
       "1  1084961  20161109.0  https://www.sec.gov/Archives/edgar/data/108496...\n",
       "2  1087934  20161109.0  https://www.sec.gov/Archives/edgar/data/108793...\n",
       "3  1091171  20161109.0  https://www.sec.gov/Archives/edgar/data/109117...\n",
       "4  1092289  20161109.0  https://www.sec.gov/Archives/edgar/data/109228..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "xml_qtr_4 = pd.read_csv('10-Q_xml_4.csv')\n",
    "xml_qtr_4.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "xml_qtr_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cik': 1084048,\n",
       "  'date': 20161109.0,\n",
       "  'xml': 'https://www.sec.gov/Archives/edgar/data/1084048/000108404816000026/FilingSummary.xml'},\n",
       " {'cik': 1084961,\n",
       "  'date': 20161109.0,\n",
       "  'xml': 'https://www.sec.gov/Archives/edgar/data/1084961/000108496116000226/FilingSummary.xml'},\n",
       " {'cik': 1087934,\n",
       "  'date': 20161109.0,\n",
       "  'xml': 'https://www.sec.gov/Archives/edgar/data/1087934/000156459016028621/FilingSummary.xml'},\n",
       " {'cik': 1091171,\n",
       "  'date': 20161109.0,\n",
       "  'xml': 'https://www.sec.gov/Archives/edgar/data/1091171/000109117116000307/FilingSummary.xml'},\n",
       " {'cik': 1092289,\n",
       "  'date': 20161109.0,\n",
       "  'xml': 'https://www.sec.gov/Archives/edgar/data/1092289/000156459016028702/FilingSummary.xml'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to list of dictionaries\n",
    "xml_list_4=xml_qtr_4.to_dict('records')\n",
    "xml_list_4[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77541"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This does the same thing as the loop above, but you can run it after loading the data if you didn't before saving\n",
    "xml_new=[]\n",
    "for i in range(len(xml_list_4)):\n",
    "  if type(xml_list_4[i]['xml'])==str:\n",
    "    xml_new.append(xml_list_4[i])\n",
    "len(xml_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function creates a master reports list\n",
    "#it uses keywords to look for balance sheets, income statements, and statements of cashflows\n",
    "def get_reports(dictionary):\n",
    "    master_reports=[]\n",
    "    time.sleep(0.5)\n",
    "    base_dict={}\n",
    "    base_dict['cik']=dictionary['cik']\n",
    "    #using the xml summary to get statement links\n",
    "    base_url = dictionary['xml'].replace('FilingSummary.xml', '')\n",
    "\n",
    "    content=requests.get(dictionary['xml'], headers={'User-Agent': 'Chrome/39.0.2171.95'}).content\n",
    "    soup=BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    reports=soup.find('myreports')\n",
    "    #to account for the link not reading correctly\n",
    "    if reports is None:\n",
    "        return base_dict\n",
    "\n",
    "    #loops through all reports in the filing and grabs the ones of interest based on the list of keywords below\n",
    "    for report in reports.find_all('report')[:-1]:\n",
    "        report_dict={}\n",
    "        report_dict['cik'] = dictionary['cik']\n",
    "        report_dict['date'] = dictionary['date']\n",
    "        report_dict['short_name'] = report.shortname.text.lower()\n",
    "        report_dict['long_name'] = report.longname.text.lower()\n",
    "        #report_dict['position'] = report.position.text.lower()\n",
    "        #report_dict['menu_category'] = report.menucategory.text.lower()\n",
    "        report_dict['url'] = base_url + report.htmlfilename.text\n",
    "\n",
    "        keyword_list= ['balance sheet', 'balance sheets', 'income statement','statement of income', \n",
    "                       'statement of comprehensive income', 'statements of income', \n",
    "                       'statements of comprehensive income','cash flows']\n",
    "        #ignore these words\n",
    "        keyword_list1=['derivative', 'parenthetical', 'note', 'notes', 'detail']\n",
    "        if any(ele in report_dict['short_name'] for ele in keyword_list1):\n",
    "            continue\n",
    "\n",
    "        elif (any(ele in report_dict['short_name'] for ele in keyword_list)):\n",
    "            master_reports.append(report_dict)\n",
    "    return master_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129.779483556747 seconds to read 76391 items.\n"
     ]
    }
   ],
   "source": [
    "master_reports = main(get_reports, new_xml, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cik': 814586,\n",
       "  'date': 20121114,\n",
       "  'long_name': '00200 - statement - consolidated statements of income and comprehensive income',\n",
       "  'short_name': 'consolidated statements of income and comprehensive income',\n",
       "  'url': 'https://www.sec.gov/Archives/edgar/data/814586/000107261312000663/R4.htm'},\n",
       " {'cik': 814586,\n",
       "  'date': 20121114,\n",
       "  'long_name': '00400 - statement - consolidated statements of cash flows',\n",
       "  'short_name': 'consolidated statements of cash flows',\n",
       "  'url': 'https://www.sec.gov/Archives/edgar/data/814586/000107261312000663/R7.htm'},\n",
       " {'cik': 814926,\n",
       "  'date': 20121114,\n",
       "  'long_name': '000020 - statement - consolidated balance sheets',\n",
       "  'short_name': 'consolidated balance sheets',\n",
       "  'url': 'https://www.sec.gov/Archives/edgar/data/814926/000093980212000267/R2.htm'},\n",
       " {'cik': 814926,\n",
       "  'date': 20121114,\n",
       "  'long_name': '000050 - statement - consolidated statements of cash flows',\n",
       "  'short_name': 'consolidated statements of cash flows',\n",
       "  'url': 'https://www.sec.gov/Archives/edgar/data/814926/000093980212000267/R5.htm'},\n",
       " {'cik': 818677,\n",
       "  'date': 20121114,\n",
       "  'long_name': '000020 - statement - security federal corporation and subsidiaries consolidated balance sheets (unaudited)',\n",
       "  'short_name': 'security federal corporation and subsidiaries consolidated balance sheets (unaudited)',\n",
       "  'url': 'https://www.sec.gov/Archives/edgar/data/818677/000093905712000332/R2.htm'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar to the xml list, this corrects for any reports that were not read in correctly\n",
    "new_master=[]\n",
    "for i in range(len(master_reports)):\n",
    "    if (len(master_reports[i])>0) and (type(master_reports[i])==list):\n",
    "        for j in range(len(master_reports[i])):\n",
    "            new_master.append(master_reports[i][j])\n",
    "new_master[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save for later\n",
    "reports_qtr = pd.DataFrame(new_master)\n",
    "reports_qtr.to_csv('10-Q_reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function uses the links in the master reports list to get the data in the reports\n",
    "def get_data(dictionary):\n",
    "    time.sleep(0.7)\n",
    "    #headers contain document title, scale of reporting, and dates\n",
    "    #sections are the main secitons of the reports\n",
    "    #data contains numerical values and subsections\n",
    "    statement_data={}\n",
    "    statement_data['cik']=dictionary['cik']\n",
    "    statement_data['headers']=[]\n",
    "    statement_data['sections']=[]\n",
    "    statement_data['data']=[]\n",
    "\n",
    "    statement = dictionary['url']\n",
    "    content=requests.get(statement, headers={'User-Agent': 'Mozilla/5.0'}).content\n",
    "    report_soup=BeautifulSoup(content, 'lxml')\n",
    "    if report_soup.table is None:\n",
    "        return statement_data\n",
    "    \n",
    "    report_soup = report_soup.table.find_all('tr')\n",
    "    for index, row in enumerate(report_soup):\n",
    "        if row is None:\n",
    "            return statement_data\n",
    "\n",
    "        cols=row.find_all('td')\n",
    "#these if statements put the sections of the reports in the right place in the dictionary\n",
    "        if (len(row.find_all('th'))==0 and len(row.find_all('strong'))==0):\n",
    "            reg_row=[ele.text.strip() for ele in cols]\n",
    "            statement_data['data'].append(reg_row)\n",
    "\n",
    "        elif (len(row.find_all('th'))==0 and len(row.find_all('strong'))!=0):\n",
    "            sec_row= cols[0].text.strip()\n",
    "            statement_data['sections'].append(sec_row)\n",
    "\n",
    "        elif (len(row.find_all('th'))!=0):\n",
    "            head_row=[ele.text.strip() for ele in row.find_all('th')]\n",
    "            statement_data['headers'].append(head_row)\n",
    "    return statement_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101785"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making it shorter for time purposes\n",
    "new_master1 = new_master[101786:203571]\n",
    "len(new_master1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statements_data=main(get_data, new_master1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setting the scale based on the values listed in headers\n",
    "for i in range(len(statements_data)):\n",
    "    if len(statements_data[i]['headers'])==0:\n",
    "        continue\n",
    "    if 'Thousands' in  statements_data[i]['headers'][0][0]:\n",
    "        statements_data[i]['scale']='thousands'\n",
    "    elif 'Millions' in  statements_data[i]['headers'][0][0]:\n",
    "        statements_data[i]['scale']='millions'\n",
    "    else:\n",
    "        statements_data[i]['scale']='ones'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of balance sheets: 39116\n",
      "Number of income statements: 24544\n",
      "Number of statements of cash flows: 38122\n"
     ]
    }
   ],
   "source": [
    "#sorting the reports by report type\n",
    "bs_data=[]\n",
    "is_data=[]\n",
    "cf_data=[]\n",
    "for i in range(len(statements_data)):\n",
    "    if len(statements_data[i]['headers'])==0:\n",
    "        continue\n",
    "    statements_data[i]['headers'][0][0] = statements_data[i]['headers'][0][0].lower()\n",
    "    if 'balance' in statements_data[i]['headers'][0][0]:\n",
    "        bs_data.append(statements_data[i])\n",
    "    elif 'income' in statements_data[i]['headers'][0][0]:\n",
    "        is_data.append(statements_data[i])\n",
    "    elif 'cash' in statements_data[i]['headers'][0][0]:\n",
    "        cf_data.append(statements_data[i])\n",
    "print('Number of balance sheets: '+ str(len(bs_data)))\n",
    "print('Number of income statements: '+ str(len(is_data)))\n",
    "print('Number of statements of cash flows: ' +str(len(cf_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a list of two row datasets for each individual balance sheet\n",
    "bs_lst=[]\n",
    "for i in range(len(bs_data)):\n",
    "    i = i\n",
    "    headers = bs_data[i]['headers'][0]\n",
    "    if len(headers)!= 3:\n",
    "        continue\n",
    "    else:\n",
    "        data = bs_data[i]['data']\n",
    "        totals=[]\n",
    "        for j in range(len(data)):\n",
    "        #manipulating the data to make the sections more uniform\n",
    "          data[j][0]=data[j][0].lower()\n",
    "          data[j][0]=data[j][0].replace(\"'\", \"\").replace(\"â€™\", '')\n",
    "          data[j][0]=data[j][0].replace('stockholders', 'shareholders').replace('deficit', 'equity')\n",
    "        #searching for the three main categories and renaming them for uniformity sake\n",
    "          if ('total assets' in data[j][0]):\n",
    "            data[j][0]='total assets'\n",
    "            totals.append(data[j])\n",
    "          elif ('total liabilities' in data[j][0]):\n",
    "            data[j][0]='total liabilities'\n",
    "            totals.append(data[j])\n",
    "          elif ('total' in data[j][0]) and (\"shareholders equity\" in data[j][0]):\n",
    "            data[j][0]='total shareholders equity'\n",
    "            totals.append(data[j])\n",
    "        if (len(totals)<3):\n",
    "            continue\n",
    "        elif (len(totals[0]) <3):\n",
    "            continue\n",
    "    #get dates, scale and cik for dataframe\n",
    "        else:\n",
    "          dates = headers[1:3]\n",
    "          cik = [bs_data[i]['cik']]*2\n",
    "          scale = [bs_data[i]['scale']]*2\n",
    "          df = pd.DataFrame(totals)\n",
    "          df = df.set_index(0).T\n",
    "          if len(df)>2:\n",
    "              continue\n",
    "          else:\n",
    "              df.insert(0, 'dates', dates)\n",
    "              df.insert(0, 'scale', scale)\n",
    "              df.insert(0, 'cik', cik)\n",
    "              df=df.loc[:,~df.columns.duplicated()]\n",
    "              bs_lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_df(df1,df2): return pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>dates</th>\n",
       "      <th>scale</th>\n",
       "      <th>total assets</th>\n",
       "      <th>total liabilities</th>\n",
       "      <th>total shareholders equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8858</td>\n",
       "      <td>Dec. 27, 2014</td>\n",
       "      <td>thousands</td>\n",
       "      <td>11,491,094us-gaap_Assets</td>\n",
       "      <td>6,786,164us-gaap_Liabilities</td>\n",
       "      <td>4,704,930us-gaap_StockholdersEquity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8858</td>\n",
       "      <td>Jun. 28, 2014</td>\n",
       "      <td>thousands</td>\n",
       "      <td>11,255,517us-gaap_Assets</td>\n",
       "      <td>6,365,324us-gaap_Liabilities</td>\n",
       "      <td>4,890,193us-gaap_StockholdersEquity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023731</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>thousands</td>\n",
       "      <td>308,018us-gaap_Assets</td>\n",
       "      <td>22,237us-gaap_Liabilities</td>\n",
       "      <td>285,781us-gaap_StockholdersEquity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023731</td>\n",
       "      <td>Mar. 31, 2014</td>\n",
       "      <td>thousands</td>\n",
       "      <td>299,203us-gaap_Assets</td>\n",
       "      <td>21,025us-gaap_Liabilities</td>\n",
       "      <td>278,178us-gaap_StockholdersEquity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040130</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>thousands</td>\n",
       "      <td>79,842us-gaap_Assets</td>\n",
       "      <td>6,295us-gaap_Liabilities</td>\n",
       "      <td>73,547us-gaap_StockholdersEquity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cik          dates      scale              total assets  \\\n",
       "0     8858  Dec. 27, 2014  thousands  11,491,094us-gaap_Assets   \n",
       "1     8858  Jun. 28, 2014  thousands  11,255,517us-gaap_Assets   \n",
       "2  1023731  Dec. 31, 2014  thousands     308,018us-gaap_Assets   \n",
       "3  1023731  Mar. 31, 2014  thousands     299,203us-gaap_Assets   \n",
       "4  1040130  Dec. 31, 2014  thousands      79,842us-gaap_Assets   \n",
       "\n",
       "              total liabilities            total shareholders equity  \n",
       "0  6,786,164us-gaap_Liabilities  4,704,930us-gaap_StockholdersEquity  \n",
       "1  6,365,324us-gaap_Liabilities  4,890,193us-gaap_StockholdersEquity  \n",
       "2     22,237us-gaap_Liabilities    285,781us-gaap_StockholdersEquity  \n",
       "3     21,025us-gaap_Liabilities    278,178us-gaap_StockholdersEquity  \n",
       "4      6,295us-gaap_Liabilities     73,547us-gaap_StockholdersEquity  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate all dataframes in the list\n",
    "bs_df = reduce(concat_df, bs_lst)\n",
    "bs_df.reset_index(inplace=True)\n",
    "bs_df.drop('index', axis=1, inplace=True)\n",
    "bs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv\n",
    "bs_df.to_csv('bs_df4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this loop puts all income statements into a list of dataframes\n",
    "#the format is the same as for the balance sheets but has code specific for the information found in an income statement\n",
    "is_lst=[]\n",
    "for i in range(len(is_data)):\n",
    "    i = i\n",
    "    headers = is_data[i]['headers'][0]\n",
    "    if len(headers)!= 3:\n",
    "        continue\n",
    "    else:\n",
    "        data = is_data[i]['data'][0:3]\n",
    "        totals=[]\n",
    "        for j in range(len(data)):\n",
    "          data[j][0]=data[j][0].lower()\n",
    "          data[j][0]=data[j][0].replace(\"loss\", \"income\")\n",
    "          #data[j][0]=data[j][0].replace('stockholders', 'shareholders').replace('deficit', 'equity')\n",
    "        #looking for net income and renaming\n",
    "          if ('net' in data[j][0]) and ('income' in data[j][0]):\n",
    "            data[j][0]='net income'\n",
    "            totals.append(data[j][0:3])\n",
    "        \n",
    "        if len(totals)==0:\n",
    "          continue\n",
    "        elif len(totals[0])<3:\n",
    "            continue\n",
    "        elif len(is_data[i]['headers'])!=2:\n",
    "            continue\n",
    "        else:\n",
    "          dates = is_data[i]['headers'][1][0:2]\n",
    "          cik = [is_data[i]['cik']]*2\n",
    "          scale = [is_data[i]['scale']]*2\n",
    "          df = pd.DataFrame(totals)\n",
    "          df = df.set_index(0).T\n",
    "          if len(df)>2:\n",
    "              continue\n",
    "          else:\n",
    "              df.insert(0, 'dates', dates)\n",
    "              df.insert(0, 'scale', scale)\n",
    "              df.insert(0, 'cik', cik)\n",
    "              df=df.loc[:,~df.columns.duplicated()]\n",
    "              is_lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>scale</th>\n",
       "      <th>dates</th>\n",
       "      <th>net income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8858</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 27, 2014</td>\n",
       "      <td>$ 163,706us-gaap_NetIncomeLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8858</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 28, 2013</td>\n",
       "      <td>$ 124,864us-gaap_NetIncomeLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023731</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>$ 444us-gaap_NetIncomeLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023731</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2013</td>\n",
       "      <td>$ 89us-gaap_NetIncomeLoss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>789019</td>\n",
       "      <td>millions</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>$ 5,863us-gaap_NetIncomeLoss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      cik      scale          dates                      net income\n",
       "0     8858  thousands  Dec. 27, 2014  $ 163,706us-gaap_NetIncomeLoss\n",
       "1     8858  thousands  Dec. 28, 2013  $ 124,864us-gaap_NetIncomeLoss\n",
       "2  1023731  thousands  Dec. 31, 2014      $ 444us-gaap_NetIncomeLoss\n",
       "3  1023731  thousands  Dec. 31, 2013       $ 89us-gaap_NetIncomeLoss\n",
       "4   789019   millions  Dec. 31, 2014    $ 5,863us-gaap_NetIncomeLoss"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenating dataframes\n",
    "is_df = reduce(concat_df, is_lst)\n",
    "is_df.reset_index(inplace=True)\n",
    "is_df.drop('index', axis=1, inplace=True)\n",
    "is_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to dataframe\n",
    "is_df.to_csv('is_df4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this loop is the same as the previous two in format but spefic to statements of cashflows\n",
    "cf_lst=[]\n",
    "for i in range(len(cf_data)):\n",
    "    i = i\n",
    "    headers = cf_data[i]['headers'][0]\n",
    "    data = cf_data[i]['data']\n",
    "    totals=[]\n",
    "    for j in range(len(data)):\n",
    "      data[j][0]=data[j][0].lower()\n",
    "      #data[j][0]=data[j][0].replace(\"loss\", \"income\")\n",
    "      #data[j][0]=data[j][0].replace('stockholders', 'shareholders').replace('deficit', 'equity')\n",
    "      if ('cash equivalents' in data[j][0]) and ('end' in data[j][0]):\n",
    "        data[j][0]='cash equivalents'\n",
    "        totals.append(data[j])\n",
    "    \n",
    "    if len(totals)==0:\n",
    "      continue\n",
    "    elif len(totals[0])<3:\n",
    "            continue\n",
    "    else:\n",
    "        if (len(cf_data[i]['headers'])==2):\n",
    "          dates = cf_data[i]['headers'][1][0:2]\n",
    "          if len(dates)==2:\n",
    "              cik = [cf_data[i]['cik']]*2\n",
    "              scale = [cf_data[i]['scale']]*2\n",
    "              df = pd.DataFrame(totals)\n",
    "              df = df.set_index(0).T\n",
    "              if len(df)>2:\n",
    "                  continue\n",
    "              else:\n",
    "                  df.insert(0, 'dates', dates)\n",
    "                  df.insert(0, 'scale', scale)\n",
    "                  df.insert(0, 'cik', cik)\n",
    "                  df=df.loc[:,~df.columns.duplicated()]\n",
    "                  cf_lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>scale</th>\n",
       "      <th>dates</th>\n",
       "      <th>cash equivalents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319201</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>584,865us-gaap_CashAndCashEquivalentsAtCarryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319201</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2013</td>\n",
       "      <td>793,382us-gaap_CashAndCashEquivalentsAtCarryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023731</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>52,598us-gaap_CashAndCashEquivalentsAtCarrying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023731</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2013</td>\n",
       "      <td>172,114us-gaap_CashAndCashEquivalentsAtCarryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1040130</td>\n",
       "      <td>thousands</td>\n",
       "      <td>Dec. 31, 2014</td>\n",
       "      <td>37,068us-gaap_CashAndCashEquivalentsAtCarrying...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      cik      scale          dates  \\\n",
       "0   319201  thousands  Dec. 31, 2014   \n",
       "1   319201  thousands  Dec. 31, 2013   \n",
       "2  1023731  thousands  Dec. 31, 2014   \n",
       "3  1023731  thousands  Dec. 31, 2013   \n",
       "4  1040130  thousands  Dec. 31, 2014   \n",
       "\n",
       "0                                   cash equivalents  \n",
       "0  584,865us-gaap_CashAndCashEquivalentsAtCarryin...  \n",
       "1  793,382us-gaap_CashAndCashEquivalentsAtCarryin...  \n",
       "2  52,598us-gaap_CashAndCashEquivalentsAtCarrying...  \n",
       "3  172,114us-gaap_CashAndCashEquivalentsAtCarryin...  \n",
       "4  37,068us-gaap_CashAndCashEquivalentsAtCarrying...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenating dataframes\n",
    "cf_df = reduce(concat_df, cf_lst)\n",
    "cf_df.reset_index(inplace=True)\n",
    "cf_df.drop('index', axis=1, inplace=True)\n",
    "cf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save as csv\n",
    "cf_df.to_csv('cf_df4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
